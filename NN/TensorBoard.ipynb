{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of how to see your learning parameters in TensorBoard\n",
    "\n",
    "The point of this code example is to show you how to record statistics during learning and display them using TensorBoard\n",
    "\n",
    "Refer to the following for additional functions (can record data/images, graphs, etc.)\n",
    "  * https://tensorboardx.readthedocs.io/en/latest/tensorboard.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd import Function\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#######################################################################################\n",
    "\n",
    "# our neural net class\n",
    "class Perceptron(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Perceptron, self).__init__()\n",
    "        self.fc1 = nn.Linear(2,1,True)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "    \n",
    "# make the neuron\n",
    "net = Perceptron()\n",
    "# net.cuda() # GPU acceleration\n",
    "\n",
    "#######################################################################################\n",
    "\n",
    "# make some synthetic data\n",
    "N = 100\n",
    "Nhalf = int( N / 2 )\n",
    "data = torch.randn(N,2) \n",
    "for i in range(Nhalf): # class 1\n",
    "    data[i,0] = data[i,0] * 0.1 + 0.2\n",
    "    data[i,1] = data[i,1] * 0.1 + 0.2\n",
    "for i in range(Nhalf): # class 2\n",
    "    data[i+Nhalf,0] = data[i+Nhalf,0] * 0.1 + -0.2\n",
    "    data[i+Nhalf,1] = data[i+Nhalf,1] * 0.1 + 0.8\n",
    "    \n",
    "# labels\n",
    "L = torch.ones(N)\n",
    "for i in range(Nhalf): # class 1\n",
    "    L[i] = 1\n",
    "for i in range(Nhalf): # class 2\n",
    "    L[i+Nhalf] = -1\n",
    "    \n",
    "#######################################################################################\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "%load_ext tensorboard\n",
    "# %reload_ext tensorboard\n",
    "writer = SummaryWriter()\n",
    "\n",
    "#######################################################################################\n",
    "\n",
    "# criteria fx\n",
    "def criterion(out,label):\n",
    "    return (label - out)**2\n",
    "\n",
    "# setup SGD optimization\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "# train\n",
    "for epoch in range(500):\n",
    "    accum=0 # sum up error per epoch\n",
    "    for i in range(N):\n",
    "        X = Variable(data[i,:])\n",
    "        Y = Variable(L[i])\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(X)\n",
    "        loss = criterion(outputs, Y)\n",
    "        accum=accum+loss # accumulate that error\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    accum=accum/N # divide by the number of objects we evaluated over\n",
    "    writer.add_scalar('loss', accum, epoch) # post that to our file for TensorBoard to analyze\n",
    "        \n",
    "#######################################################################################\n",
    "\n",
    "%tensorboard --logdir runs        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
