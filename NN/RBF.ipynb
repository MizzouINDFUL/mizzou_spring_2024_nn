{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904a7a16-ac7d-4e8b-a074-8f1e2902d96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebaf55c-115e-4463-96f3-b859b9bd050d",
   "metadata": {},
   "source": [
    "Lets play around with a simple RBF network\n",
    "\n",
    "First, lets generate some data (toy data set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1437cd84-0dfe-4f8e-b665-d04dc2c89469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd import Function\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# lets use sklearn to make 'blob' patterns (for a train set)\n",
    "x1, junk = make_blobs(n_samples=400, centers=4, cluster_std=0.5, random_state=1)\n",
    "x2, junk = make_blobs(n_samples=500, centers=5, cluster_std=0.5, random_state=667)\n",
    "y1 = np.zeros(x1.shape[0]).astype(np.float64)\n",
    "y2 = np.ones(x2.shape[0]).astype(np.float64)\n",
    "plt.scatter(x1[:, 0], x1[:, 1], cmap='ob')\n",
    "plt.scatter(x2[:, 0], x2[:, 1], cmap='or')\n",
    "plt.show()\n",
    "\n",
    "# combine \n",
    "xtrain = np.concatenate( (x1, x2) )\n",
    "ytrain = np.concatenate( (y1, y2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0293ee40-c21d-4dee-98fd-ef2770e3d813",
   "metadata": {},
   "source": [
    "Now, a test set, slightly larger std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f307976a-8514-462f-9b17-61cb1286576a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets use sklearn to make 'blob' patterns\n",
    "tx1, junk = make_blobs(n_samples=80, centers=4, cluster_std=0.7, random_state=1)\n",
    "tx2, junk = make_blobs(n_samples=100, centers=5, cluster_std=0.7, random_state=667)\n",
    "ty1 = np.zeros(tx1.shape[0]).astype(np.float64)\n",
    "ty2 = np.ones(tx2.shape[0]).astype(np.float64)\n",
    "plt.scatter(tx1[:, 0], tx1[:, 1], cmap='ob')\n",
    "plt.scatter(tx2[:, 0], tx2[:, 1], cmap='or')\n",
    "plt.show()\n",
    "\n",
    "# combine \n",
    "xtest = np.concatenate( (tx1, tx2) )\n",
    "ytest = np.concatenate( (ty1, ty2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd01b94-cdae-46b4-befd-318b3352e878",
   "metadata": {},
   "source": [
    "Now, we will cluster our data and create the RBFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ad3485-388b-4b73-a45f-0a41cecac52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# a plot helper routine\n",
    "def plot_kmeans(kmeans, X, n_clusters=4, rseed=0, ax=None):\n",
    "    labels = kmeans.fit_predict(X)\n",
    "    # plot the input data\n",
    "    ax = ax or plt.gca()\n",
    "    ax.axis('equal')\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap='viridis', zorder=2)\n",
    "    # plot the representation of the KMeans model\n",
    "    centers = kmeans.cluster_centers_\n",
    "    radii = [cdist(X[labels == i], [center]).max()\n",
    "             for i, center in enumerate(centers)]\n",
    "    for c, r in zip(centers, radii):\n",
    "        ax.add_patch(plt.Circle(c, r, fc='#CCCCCC', lw=3, alpha=0.8, zorder=1))\n",
    "\n",
    "# cluster class 1\n",
    "kmeans = KMeans(9, random_state=0)\n",
    "kmeans.fit(xtrain)\n",
    "klabels = kmeans.predict(xtrain)\n",
    "plot_kmeans(kmeans, xtrain, n_clusters=9)\n",
    "plt.show()\n",
    "\n",
    "clusters = kmeans.cluster_centers_.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c825e51-f632-446c-9918-e8be7c705a7e",
   "metadata": {},
   "source": [
    "Now, lets seed those RBFs\n",
    "\n",
    "Make design our RBF network, init it with means, unit sigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38546aee-16b7-417f-b67e-3f9170750baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make network\n",
    "class RBFnet(nn.Module):\n",
    "    def __init__(self, clusters):\n",
    "        super(RBFnet, self).__init__()\n",
    "        # remember how many centers we have\n",
    "        self.N = clusters.shape[0]\n",
    "        # our mean and sigmas for the RBF layer\n",
    "        self.sigs = nn.Parameter( torch.ones(self.N,dtype=torch.float64)*5, requires_grad=False ) # our sigmas\n",
    "        self.mus = nn.Parameter( torch.from_numpy(clusters), requires_grad=False ) # our means\n",
    "        # our connection to the output layer\n",
    "        self.lin = nn.Parameter( ((torch.rand(self.N,dtype=torch.float64)-0.5)*2.0)*(1.0/self.N), requires_grad=True)\n",
    "        self.bias = nn.Parameter( ((torch.rand(1,dtype=torch.float64)-0.5)*2.0)*(1.0/self.N), requires_grad=True)\n",
    "    def forward(self, x):\n",
    "        # evaluate RBFs\n",
    "        # you could do some matrix math and get rid of this for loop!!!!\n",
    "        res = torch.zeros(x.shape[0],self.N,dtype=torch.float64)\n",
    "        for i in range(x.shape[0]): # each data point\n",
    "            for j in range(self.N): # each cluster\n",
    "                top = torch.sqrt(((x[i,:]-self.mus[j,:])**2).sum(axis=0))\n",
    "                res[i,j] = torch.exp( (-0.5) * ( torch.pow(top,2.0) / torch.pow(self.sigs[j],2.0) ) )\n",
    "        y_pred = torch.zeros(x.shape[0],dtype=torch.float64)\n",
    "        for i in range(x.shape[0]): # again, could speed up with matrix math!!!\n",
    "            y_pred[i] = torch.sigmoid( torch.dot(res[i,:],self.lin) + self.bias )\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c7fa16-3593-4690-a77a-a4ea9b31deb0",
   "metadata": {},
   "source": [
    "Lets make our data set and do mini batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df94b8c-516f-41fb-b9cb-fe51cc0b3f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_utils import Format_Dataset\n",
    "\n",
    "# mini-batch training\n",
    "dataset = {'samples': xtrain, 'labels': ytrain} \n",
    "train = Format_Dataset(dataset, choice = 'Train')\n",
    "train = torch.utils.data.DataLoader( shuffle = True,\n",
    "                                        dataset = train, \n",
    "                                        batch_size = 10 ) # here is our mini-batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f9b74f-d677-4656-8a4e-90c9183e6705",
   "metadata": {},
   "source": [
    "Lets build our network and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e829212c-267e-4b15-a482-815d0f4d6504",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# 2 inputs, 1 output, and init with our clusters\n",
    "net = RBFnet(clusters)\n",
    "\n",
    "# criteria function, sum of squared error\n",
    "criterion = nn.MSELoss()\n",
    "# lets just go with stochastic gradient descent\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.1)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 200\n",
    "for epoch in tqdm(range(num_epochs),'Training Epochs'): # train for num_epochs     \n",
    "    for samples, labels in train: # our mini batch sampling\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = net(samples) # what outputs given our current weights?    \n",
    "        loss = criterion(outputs, labels) # evaluate the loss\n",
    "\n",
    "        # Backward error and optimize!\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Plot the graph\n",
    "predicted = net(torch.from_numpy(xtest)).detach().numpy()\n",
    "plt.stem(ytest, linefmt ='grey', markerfmt ='D', use_line_collection = True)\n",
    "plt.stem(predicted, linefmt ='blue', markerfmt ='D', use_line_collection = True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b067ae-8bb2-451c-ba9c-f9501d6cbbdf",
   "metadata": {},
   "source": [
    "What were the final net parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4115ec1d-4815-4c7f-a4ee-105f2c327942",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(net.parameters())) # print var values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcfc025-5dad-4b3a-8879-1fb3c7f9728d",
   "metadata": {},
   "source": [
    "What if we go right after it with LMS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7b46a9-ee2d-43bc-8b5a-40626c320e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from numpy.linalg import inv\n",
    "\n",
    "# lets run our data through our radial basis functions\n",
    "def eval_on_data(x,clusters):\n",
    "    # evaluate RBFs\n",
    "    # you could do some matrix math and get rid of this for loop!!!!\n",
    "    res = np.zeros((x.shape[0],clusters.shape[0]))\n",
    "    for i in range(x.shape[0]): # each data point\n",
    "        for j in range(clusters.shape[0]): # each cluster\n",
    "            top = np.sqrt(((x[i,:]-clusters[j,:])**2).sum(axis=0))\n",
    "            res[i,j] = np.exp( (-0.5) * ( math.pow(top,2.0) / math.pow(1.0,2.0) ) ) # sigma = 1 assumption here\n",
    "    return res\n",
    "            \n",
    "outputs = eval_on_data(xtrain,clusters)\n",
    "\n",
    "# our target output values are \n",
    "#  ytrain\n",
    "\n",
    "# use a LMS solver to determine our weights\n",
    "#  A_psinv = inv(tran(A) * A) * tran(A)\n",
    "PSINV = np.matmul( inv( np.matmul(outputs.transpose(),outputs) ), outputs.transpose() )\n",
    "weights = np.matmul( PSINV, ytrain )\n",
    "\n",
    "# eval now on this\n",
    "testres = np.zeros(xtest.shape[0])\n",
    "for i in range(xtest.shape[0]): # each sample\n",
    "    code = np.zeros(clusters.shape[0])\n",
    "    for j in range(clusters.shape[0]): # each cluster\n",
    "        top = np.sqrt(((xtest[i,:]-clusters[j,:])**2).sum(axis=0))\n",
    "        code[j] = np.exp( (-0.5) * ( math.pow(top,2.0) / math.pow(1.0,2.0) ) ) # sigma = 1 assumption here\n",
    "    # now, mult by our weights\n",
    "    testres[i] = np.dot( code, weights )\n",
    "plt.stem(ytest, linefmt ='grey', markerfmt ='D', use_line_collection = True)\n",
    "plt.stem(testres, linefmt ='blue', markerfmt ='D', use_line_collection = True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
